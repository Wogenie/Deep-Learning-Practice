{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Harder Image Datasets  \n",
        "> Increase the accuracy using different methods\n"
      ],
      "metadata": {
        "id": "BZilKJw71POJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# datasets\n",
        "1) CIFAR-10 - 20 classes\n",
        "2) CIFAR-100 (Much Harder)- 100 classes\n",
        "3) Tiny ImageNet (Serious Challenge) > 300 classes"
      ],
      "metadata": {
        "id": "4NrfTrCd1e8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) MNIST datasets using NN and CNN both"
      ],
      "metadata": {
        "id": "MfprHhDe4D0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import datasets\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "d2jOXh964DCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "digits = load_digits()\n",
        "data = digits.data\n",
        "target = digits.target\n",
        "data.shape, target.shape"
      ],
      "metadata": {
        "id": "L8iks8ae4C9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "73pa1Jrg5eDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# scale the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "X_test.max()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RN503sMk4C5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "AKIHZn7A59j5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "from keras import regularizers"
      ],
      "metadata": {
        "id": "eXgpsFTD4C1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nn_model = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(64,)),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "nn_model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=0.01),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "# fit the model\n",
        "\n",
        "History = nn_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,\n",
        "    validation_split=0.2,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "_llJu-hf4CxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_model.summary()"
      ],
      "metadata": {
        "id": "bhGDJSe9DeKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_history(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    for key, value in history.history.items():\n",
        "        label_name =f'{key}: {round(value[0],2)} => {round(value[-1], 2) }'\n",
        "        plt.subplot(1, 2, 1)\n",
        "        accuracy = round(history.history['val_accuracy'][-1]*100 , 1)\n",
        "        plt.plot(value, label=label_name)\n",
        "        plt.legend()\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.grid(True)\n",
        "    plt.title(f\"Digit Recognition using NN, accuracy = {accuracy}%\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_history(History)\n"
      ],
      "metadata": {
        "id": "P38vTgzL6ZT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "NucgVss_4j6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second model cnn"
      ],
      "metadata": {
        "id": "FQ3oYIhHFM5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_reshaped = X_train.reshape(-1, 8, 8, 1)\n",
        "X_test_reshaped = X_test.reshape(-1, 8, 8, 1)\n",
        "print(X_train_reshaped.shape)\n",
        "print(X_test_reshaped.shape)\n",
        "\n",
        "\n",
        "y_train_reshaped = y_train.reshape(-1, 1)\n",
        "y_test_reshaped = y_test.reshape(-1, 1)\n",
        "\n",
        "\n",
        "print(y_train_reshaped.shape)\n",
        "print(y_test_reshaped.shape)"
      ],
      "metadata": {
        "id": "qtPoAvICGv4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cnn_model = models.Sequential([\n",
        "\n",
        "    # CNN architecture\n",
        "    layers.Conv2D(filters=32, kernel_size=(3,3), strides=1, activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "\n",
        "    # Fully connected layers\n",
        "    # layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=0.01),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "cnn_history = cnn_model.fit(\n",
        "    X_train_reshaped, y_train_reshaped,\n",
        "    epochs=30,\n",
        "    validation_split=0.2,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        ""
      ],
      "metadata": {
        "id": "eEMFk4BZ4j18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_history(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    for key, value in history.history.items():\n",
        "        label_name =f'{key}: {round(value[0],2)} => {round(value[-1], 2) }'\n",
        "        plt.subplot(1, 2, 1)\n",
        "        accuracy = round(history.history['val_accuracy'][-1]*100 , 1)\n",
        "        plt.plot(value, label=label_name)\n",
        "        plt.legend()\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.grid(True)\n",
        "    plt.title(f\"Digit Recognition using CNN, accuracy = {accuracy}%\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_history(cnn_history)\n"
      ],
      "metadata": {
        "id": "Ahyd_p9K4jxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.evaluate(X_test_reshaped, y_test_reshaped)"
      ],
      "metadata": {
        "id": "ec3WckmPLanO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) 10 Class model using both NN and CNN"
      ],
      "metadata": {
        "id": "C4NgtKEV-zcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# delete all the parameters above\n",
        "del nn_model\n",
        "del cnn_model\n",
        "del History\n",
        "del cnn_history\n",
        "del X_train_reshaped, X_test_reshaped, y_train_reshaped, y_test_reshaped\n"
      ],
      "metadata": {
        "id": "qHZgtks5Lju_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del X_train"
      ],
      "metadata": {
        "id": "-0SiBhOpMBt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del  X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "47XnflsqMJ7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "metadata": {
        "id": "9RwaIDkp6gxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "oin3ZmtO0kSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural network model"
      ],
      "metadata": {
        "id": "PQxqFRzRMl1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = X_train[4:14]\n",
        "y_l = y_train[4:14]\n",
        "\n",
        "def draw_10_images(s, labels):\n",
        "    plt.figure(figsize=(10, 5)) # Add figure creation for better plotting\n",
        "    for i, img_data in enumerate(s):\n",
        "        img = img_data / 255.0 # Ensure float division for image normalization\n",
        "        plt.subplot(2, 5, i+1)\n",
        "        plt.imshow(img)\n",
        "\n",
        "        index = int(labels[i])\n",
        "        plt.title(classes[index])\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "draw_10_images(s, y_l)"
      ],
      "metadata": {
        "id": "KZ1fd6Ts0j_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process the data"
      ],
      "metadata": {
        "id": "XqVkKE2C_Fx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled = X_train / 255.0\n",
        "X_test_scaled = X_test / 255.0"
      ],
      "metadata": {
        "id": "mBbXWPno0j0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled.shape, X_test_scaled.shape"
      ],
      "metadata": {
        "id": "4tCtuBqVOjuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Model Building"
      ],
      "metadata": {
        "id": "cYj81Fdk_Lr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "QiNCr6dHCpTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras import regularizers\n",
        "\n",
        "from keras import callbacks"
      ],
      "metadata": {
        "id": "cydk6vi7P8js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NN model\n"
      ],
      "metadata": {
        "id": "I4ZiqHeVP317"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nn_model = Sequential([\n",
        "    layers.Flatten(input_shape=(32, 32, 3)),\n",
        "\n",
        "    layers.Dense(1024, activation='relu'),\n",
        "    layers.Dense(500, activation='relu'),\n",
        "    layers.Dense(100, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "\n",
        "])\n",
        "\n",
        "nn_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "nn_history = nn_model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    epochs=20,\n",
        "    validation_split=0.2,\n",
        "    batch_size=64,\n",
        "    verbose=1\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "jgpGYCTvP2Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_history(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    for key, value in history.history.items():\n",
        "        label_name =f'{key}: {round(value[0],2)} => {round(value[-1], 2) }'\n",
        "        plt.subplot(1, 2, 1)\n",
        "        accuracy = round(history.history['val_accuracy'][-1]*100 , 1)\n",
        "        plt.plot(value, label=label_name)\n",
        "        plt.legend()\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.grid(True)\n",
        "    plt.title(f\"100 class using NN, accuracy = {accuracy}%\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_history(nn_history)\n"
      ],
      "metadata": {
        "id": "45oLCGIF0jw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l4jt08nlgaEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN model"
      ],
      "metadata": {
        "id": "2vc91sgzhget"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "URnGqRJWhjKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cnn_model = Sequential([\n",
        "    layers.Conv2D(filters=32, activation='relu', kernel_size=(3,3), strides=1,input_shape=(32, 32, 3)),\n",
        "    layers.MaxPool2D((2,2)),\n",
        "\n",
        "    layers.Conv2D(filters=64, activation='relu', kernel_size=(3,3), strides=1),\n",
        "    layers.MaxPool2D((2,2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(100, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = cnn_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=20,\n",
        "    validation_split=0.2,\n",
        "    batch_size=64,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "LeiZMOeohkLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S2SEbcPghjFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pq9n6whghjA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GvMm8HPhhi8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9R-Ce_VVhi3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) problem- CIFAR 100 Classes"
      ],
      "metadata": {
        "id": "S_djh41_UalH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.datasets import cifar100\n",
        "\n",
        "# (X_train, y_train), (X_test, y_test) = cifar100.load_data()"
      ],
      "metadata": {
        "id": "QNhr2uS35MMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "id": "Y_Ouc3VC5MJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xc-yobH55MF0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}